## ğŸ“ HÆ°á»›ng Dáº«n Thiáº¿t Láº­p vÃ  Cháº¡y Dá»± Ãn 

### 1\. Chuáº©n bá»‹ Dá»¯ liá»‡u

Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n cá»§a báº¡n (nÆ¡i chá»©a `docker-compose.yml`) cÃ³ cÃ¡c thÆ° má»¥c sau:

```
realtime-violence-detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ metadata/
â”‚   â”‚   â””â”€â”€ camera_registry.csv  <-- CHá»¨A DANH SÃCH CAMERA VÃ€ PLAYLIST
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ clips_for_streaming/ <-- CHá»¨A CÃC FILE VIDEO (.avi, .mp4)
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ scripts/
    â””â”€â”€ simulate_rtsp_streams.py
    â””â”€â”€ rtsp_frame_publisher.py (Producer)
    â””â”€â”€ kafka_parquet_sink.py (Consumer/Spark Job)
```

-----

### 2\. Thiáº¿t láº­p Biáº¿n mÃ´i trÆ°á»ng vÃ  Cá»•ng

Dá»± Ã¡n sá»­ dá»¥ng cá»•ng sau trÃªn mÃ¡y Host cá»§a báº¡n (Ä‘Ã£ Ä‘Æ°á»£c map trong `docker-compose.yml`):

| Dá»‹ch vá»¥ | Cá»•ng Host | Má»¥c Ä‘Ã­ch |
| :--- | :--- | :--- |
| **MediaMTX (RTSP)** | `8554` | Xem luá»“ng trá»±c tiáº¿p báº±ng VLC. |
| **MediaMTX (HTTP)** | `8888` | Xem luá»“ng trÃªn Web Dashboard (HLS/DASH). |
| **Spark UI** | `8080` | GiÃ¡m sÃ¡t Spark Master. |
| **MinIO** | `9001` | Truy cáº­p Dashboard MinIO (Web). |
| **Kafka** | `9092` | (Chá»‰ ná»™i bá»™) |

-----

### 3\. Build vÃ  Khá»Ÿi Ä‘á»™ng Táº¥t cáº£ Dá»‹ch vá»¥

Chuyá»ƒn Ä‘áº¿n thÆ° má»¥c chá»©a `docker-compose.yml` (vÃ­ dá»¥: `realtime-violence-detection\docker`) vÃ  cháº¡y lá»‡nh:

```bash
docker compose up -d --build
```

Lá»‡nh nÃ y sáº½:

1.  Táº£i vÃ  build táº¥t cáº£ cÃ¡c images cáº§n thiáº¿t (bao gá»“m cáº£ **Spark** Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh Kafka/S3A JARs).
2.  Khá»Ÿi táº¡o cÃ¡c dá»‹ch vá»¥.
3.  **Tá»± Ä‘á»™ng** khá»Ÿi Ä‘á»™ng Kafka server vÃ  cháº¡y script Python trong `rtsp_pusher` vÃ  `producer`.

-----

### 4\. Táº¡o Kafka Topics (Thá»§ cÃ´ng)

Náº¿u báº¡n Ä‘Ã£ lÃ m theo hÆ°á»›ng dáº«n sá»­a lá»—i vÃ  **tÃ¡ch viá»‡c táº¡o topics**, báº¡n cáº§n cháº¡y lá»‡nh nÃ y Ä‘á»ƒ khá»Ÿi táº¡o 2 topics cáº§n thiáº¿t:

```bash
docker exec kafka /usr/local/bin/create-topics.sh
```

-----

### 5\. Kiá»ƒm tra Luá»“ng Dá»¯ liá»‡u (Dá»± Ã¡n Ä‘Ã£ cháº¡y)

Sau khi táº¥t cáº£ container cháº¡y á»•n Ä‘á»‹nh:

#### 5.1. Kiá»ƒm tra RTSP Stream (MediaMTX)

Kiá»ƒm tra xem cÃ¡c luá»“ng video Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº©y lÃªn MediaMTX chÆ°a:

  * **Sá»­ dá»¥ng VLC:** Má»Ÿ luá»“ng máº¡ng vá»›i Ä‘á»‹a chá»‰:
    `rtsp://localhost:8554/cam_01` (thay `cam_01` báº±ng ID camera cá»§a báº¡n).

#### 5.2. Kiá»ƒm tra MinIO (S3 Storage)

  * **Truy cáº­p Dashboard MinIO:** Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p `http://localhost:9001`
  * **ÄÄƒng nháº­p:** Sá»­ dá»¥ng thÃ´ng tin Ä‘Äƒng nháº­p Ä‘Ã£ cáº¥u hÃ¬nh trong `docker-compose.yml`.
  * **Kiá»ƒm tra Bucket:** Kiá»ƒm tra bucket `violence-frames` Ä‘á»ƒ xem cÃ¡c file áº£nh (`.jpg`) cá»§a tá»«ng khung hÃ¬nh.

#### 5.3. Kiá»ƒm tra Kafka (Dá»¯ liá»‡u Luá»“ng)

Kiá»ƒm tra xem Producer cÃ³ Ä‘ang gá»­i message lÃªn Kafka khÃ´ng:

```bash
docker exec -it kafka kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic ingest.media.events --from-beginning
```

-----

### 6\. ğŸ’¾ Xá»­ lÃ½ vÃ  LÆ°u trá»¯ Dá»¯ liá»‡u (Spark)

ÄÃ¢y lÃ  bÆ°á»›c cháº¡y á»©ng dá»¥ng Spark Structured Streaming Ä‘á»ƒ tiÃªu thá»¥ káº¿t quáº£ tá»« Kafka vÃ  ghi thÃ nh Parquet vÃ o MinIO.

#### 6.1. Cháº¡y Spark Streaming Job

Thá»±c thi lá»‡nh sau Ä‘Ã¢y trong terminal trÃªn mÃ¡y host Ä‘á»ƒ cháº¡y á»©ng dá»¥ng `kafka_parquet_sink.py` trÃªn cluster Spark:

```bash
docker exec -it spark-master bash -lc "/opt/bitnami/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.pyspark.python=/opt/bitnami/python/bin/python3 \
    --conf spark.pyspark.driver.python=/opt/bitnami/python/bin/python3 \
    --conf spark.driver.host=spark-master \
    --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider \
    --conf spark.hadoop.fs.s3a.access.key=minio \
    --conf spark.hadoop.fs.s3a.secret.key=mypassword \
    --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
    --conf spark.hadoop.fs.s3a.path.style.access=true \
    --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false \
    /opt/bitnami/spark/scripts/kafka_parquet_sink.py"
```
hoáº·c
```
docker exec -it spark-master bash -lc "/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 --conf spark.pyspark.python=/opt/bitnami/python/bin/python3 --conf spark.pyspark.driver.python=/opt/bitnami/python/bin/python3 --conf spark.driver.host=spark-master --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.hadoop.fs.s3a.access.key=minio --conf spark.hadoop.fs.s3a.secret.key=mypassword --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false /opt/bitnami/spark/scripts/kafka_parquet_sink.py"

```

#### 6.2. XÃ¡c nháº­n Dá»¯ liá»‡u ÄÃ£ Ghi vÃ o MinIO

Sau khi job cháº¡y Ä‘Æ°á»£c má»™t lÃºc, dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c ghi vÃ o MinIO. Sá»­ dá»¥ng Spark Shell Ä‘á»ƒ kiá»ƒm tra:

1.  **Khá»Ÿi Ä‘á»™ng Spark Shell:**

    ```bash
    docker exec -it spark-master bash -lc "/opt/bitnami/spark/bin/spark-shell"
    ```

2.  **Äá»c vÃ  Hiá»ƒn thá»‹ Dá»¯ liá»‡u (trong Spark Shell):**

    ```scala
    val df = spark.read.parquet("s3a://inference-results/data/")
    df.show(5)
    ```

    *Náº¿u dá»¯ liá»‡u hiá»ƒn thá»‹ thÃ nh cÃ´ng, luá»“ng xá»­ lÃ½ cá»§a báº¡n Ä‘Ã£ hoáº¡t Ä‘á»™ng hoÃ n chá»‰nh.*

-----

## Dá»«ng Dá»± Ã¡n

Äá»ƒ dá»«ng vÃ  gá»¡ bá» táº¥t cáº£ cÃ¡c services, cháº¡y lá»‡nh:

```bash
docker compose down
```
