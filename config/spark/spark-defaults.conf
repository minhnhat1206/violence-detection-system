# =========================
# Spark Core
# =========================
spark.master                        spark://spark-master:7077
spark.app.name                      ViolenceDetectionPipeline
spark.submit.deployMode             client

# =========================
# Resource Management (16GB RAM)
# =========================
spark.driver.memory                 1g
spark.executor.memory               1g
spark.executor.cores                1
spark.cores.max                     1
spark.executor.memoryOverhead       256m

# =========================
# Logging
# =========================
spark.eventLog.enabled              true
spark.eventLog.dir                  file:///opt/bitnami/spark/events

# =========================
# Streaming
# =========================
spark.sql.streaming.forceDeleteTempCheckpointLocation true
spark.streaming.stopGracefullyOnShutdown true

# =========================
# REQUIRED JARS 
# =========================
spark.jars.packages                 \
org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.4,\
org.apache.hadoop:hadoop-aws:3.3.4,\
org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.1

# =========================
# Iceberg
# =========================
spark.sql.extensions                org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.iceberg           org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.type      hive
spark.sql.catalog.iceberg.uri       thrift://hive-metastore:9083
spark.sql.catalog.iceberg.warehouse s3a://inference-results/iceberg_warehouse/

# =========================
# S3A / MinIO
# =========================
spark.hadoop.fs.s3a.impl                        org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.endpoint                   http://minio:9000
spark.hadoop.fs.s3a.access.key                 minio
spark.hadoop.fs.s3a.secret.key                 mypassword
spark.hadoop.fs.s3a.path.style.access          true
spark.hadoop.fs.s3a.connection.ssl.enabled     false
spark.hadoop.fs.s3a.aws.credentials.provider   org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.fast.upload                true

# =========================
# SQL / Performance
# =========================
spark.sql.parquet.compression.codec snappy
spark.serializer                    org.apache.spark.serializer.KryoSerializer
spark.sql.shuffle.partitions        2
spark.default.parallelism           2

# =========================
# Stability
# =========================
spark.network.timeout               800s
spark.executor.heartbeatInterval    60s
spark.rpc.message.maxSize           256
spark.sql.broadcastTimeout          3600

spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
